{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# To reload external scripts automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import sys\n",
    "sns.set_context('notebook')\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from IPython.display import display\n",
    "\n",
    "# Importing external files\n",
    "sys.path.append('scripts/')\n",
    "from data_import import *\n",
    "from similarities import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-Exploratory\n",
    "This notebook contain the first study of the data to identify what is needed and what we do not need. It will only work with subsets of datasets as they will not fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../../Project-Data/\"\n",
    "META_FOLDER = DATA_FOLDER + \"meta/\"\n",
    "REVIEWS_FOLDER = DATA_FOLDER + \"reviews/\"\n",
    "CORE_FOLDER = DATA_FOLDER + \"5_core/\"\n",
    "DUMP_FOLDER = DATA_FOLDER + \"dump/\"\n",
    "CATEGORIES = ['Books','Movies_and_Tv','Electronics']\n",
    "MAXCOUNT = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0-Content of the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different columns of the **metadata** files are : \n",
    "* ```asin``` : the unique identifier of the object\n",
    "* ```brand```\n",
    "* ```categories``` : the categories of the object\n",
    "* ```description``` : the description of the object\n",
    "* ```imUrl```  : the link toward the images related to the object\n",
    "* ```price```\n",
    "* ```related``` : a list of objects that are related to this object\n",
    "* ```salesRank``` \n",
    "* ```title```\n",
    "\n",
    "The different columns of the **reviews** and **5-core** files are :\n",
    "* ```asin``` : the unique identifier of the object\n",
    "* ```helpful``` : a list of 2 integers [x,y], the helpfulness score is x/y votes\n",
    "* ```overall``` : the rating of the object\n",
    "* ```reviewText```\n",
    "* ```reviewTime```\n",
    "* ```reviewerID```\n",
    "* ```reviewerName```\n",
    "* ```summary ``` : the title of the review\n",
    "* ```unixReviewTime``` : in Unix format\n",
    "\n",
    "Therefore we keep only the column that are of interest for our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_interesting_cols = ['asin', 'title', 'salesRank', 'description','imUrl']\n",
    "review_interesting_cols = ['asin', 'overall', 'unixReviewTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1-Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths : \n",
      "\t meta = ../../Project-Data/meta/meta_Books.json\n",
      "\t review = ../../Project-Data/reviews/reviews_Books.json\n",
      "\t core_path = ../../Project-Data/5_core/Books.json\n"
     ]
    }
   ],
   "source": [
    "meta_books_path, review_books_path, core_book_path = get_paths(0, DATA_FOLDER, META_FOLDER,CORE_FOLDER,\n",
    "                                               REVIEWS_FOLDER, CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.1-Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving from : ../../Project-Data/dump/meta_Books_asin_title_salesRank_description_imUrl_ALL\n",
      "It took 00:00:04.454 to import the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>salesRank_Arts,_Crafts_&amp;_Sewing</th>\n",
       "      <th>salesRank_Books</th>\n",
       "      <th>salesRank_Cell_Phones_&amp;_Accessories</th>\n",
       "      <th>salesRank_Clothing</th>\n",
       "      <th>salesRank_Electronics</th>\n",
       "      <th>salesRank_Health_&amp;_Personal_Care</th>\n",
       "      <th>salesRank_Home_&amp;_Kitchen</th>\n",
       "      <th>...</th>\n",
       "      <th>salesRank_Jewelry</th>\n",
       "      <th>salesRank_Kitchen_&amp;_Dining</th>\n",
       "      <th>salesRank_Movies_&amp;_TV</th>\n",
       "      <th>salesRank_Music</th>\n",
       "      <th>salesRank_Musical_Instruments</th>\n",
       "      <th>salesRank_Office_Products</th>\n",
       "      <th>salesRank_Shoes</th>\n",
       "      <th>salesRank_Sports_&amp;_Outdoors</th>\n",
       "      <th>salesRank_Toys_&amp;_Games</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001048791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MKP0T4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6334800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001048775</td>\n",
       "      <td>William Shakespeare is widely regarded as the ...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/5166EBHD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13243226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Measure for Measure: Complete &amp; Unabridged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001048236</td>\n",
       "      <td>\"One thing is certain, Sherlockians, put aside...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51DH145C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8973864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Sherlock Holmes Audio Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000401048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41bchvIf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6448843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The rogue of publishers' row;: Confessions of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001019880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61LcHUdv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9589258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classic Soul Winner's New Testament Bible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                        description  \\\n",
       "0  0001048791                                                NaN   \n",
       "1  0001048775  William Shakespeare is widely regarded as the ...   \n",
       "2  0001048236  \"One thing is certain, Sherlockians, put aside...   \n",
       "3  0000401048                                                NaN   \n",
       "4  0001019880                                                NaN   \n",
       "\n",
       "                                               imUrl  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MKP0T4...   \n",
       "1  http://ecx.images-amazon.com/images/I/5166EBHD...   \n",
       "2  http://ecx.images-amazon.com/images/I/51DH145C...   \n",
       "3  http://ecx.images-amazon.com/images/I/41bchvIf...   \n",
       "4  http://ecx.images-amazon.com/images/I/61LcHUdv...   \n",
       "\n",
       "   salesRank_Arts,_Crafts_&_Sewing  salesRank_Books  \\\n",
       "0                              NaN        6334800.0   \n",
       "1                              NaN       13243226.0   \n",
       "2                              NaN        8973864.0   \n",
       "3                              NaN        6448843.0   \n",
       "4                              NaN        9589258.0   \n",
       "\n",
       "   salesRank_Cell_Phones_&_Accessories  salesRank_Clothing  \\\n",
       "0                                  NaN                 NaN   \n",
       "1                                  NaN                 NaN   \n",
       "2                                  NaN                 NaN   \n",
       "3                                  NaN                 NaN   \n",
       "4                                  NaN                 NaN   \n",
       "\n",
       "   salesRank_Electronics  salesRank_Health_&_Personal_Care  \\\n",
       "0                    NaN                               NaN   \n",
       "1                    NaN                               NaN   \n",
       "2                    NaN                               NaN   \n",
       "3                    NaN                               NaN   \n",
       "4                    NaN                               NaN   \n",
       "\n",
       "   salesRank_Home_&_Kitchen  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "\n",
       "                         ...                          salesRank_Jewelry  \\\n",
       "0                        ...                                        NaN   \n",
       "1                        ...                                        NaN   \n",
       "2                        ...                                        NaN   \n",
       "3                        ...                                        NaN   \n",
       "4                        ...                                        NaN   \n",
       "\n",
       "   salesRank_Kitchen_&_Dining  salesRank_Movies_&_TV  salesRank_Music  \\\n",
       "0                         NaN                    NaN              NaN   \n",
       "1                         NaN                    NaN              NaN   \n",
       "2                         NaN                    NaN              NaN   \n",
       "3                         NaN                    NaN              NaN   \n",
       "4                         NaN                    NaN              NaN   \n",
       "\n",
       "   salesRank_Musical_Instruments  salesRank_Office_Products  salesRank_Shoes  \\\n",
       "0                            NaN                        NaN              NaN   \n",
       "1                            NaN                        NaN              NaN   \n",
       "2                            NaN                        NaN              NaN   \n",
       "3                            NaN                        NaN              NaN   \n",
       "4                            NaN                        NaN              NaN   \n",
       "\n",
       "   salesRank_Sports_&_Outdoors  salesRank_Toys_&_Games  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "3                          NaN                     NaN   \n",
       "4                          NaN                     NaN   \n",
       "\n",
       "                                               title  \n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...  \n",
       "1         Measure for Measure: Complete & Unabridged  \n",
       "2               The Sherlock Holmes Audio Collection  \n",
       "3  The rogue of publishers' row;: Confessions of ...  \n",
       "4          Classic Soul Winner's New Testament Bible  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_books = import_interesting_cols(meta_books_path,DUMP_FOLDER,True,meta_interesting_cols,max_count=MAXCOUNT)\n",
    "meta_books.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 0.1.2-Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the JSON \\"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7b05523f6e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m review_books = import_interesting_cols(\n\u001b[0;32m----> 2\u001b[0;31m     review_books_path, DUMP_FOLDER,False, review_interesting_cols, max_count=MAXCOUNT)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreview_books\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hmoreau/Google Drive/Etudes/Master/Master-3/ADA/ADA-killer-team/project/scripts/data_import.py\u001b[0m in \u001b[0;36mimport_interesting_cols\u001b[0;34m(path, dump_folder_path, isMeta, interesting_cols, max_count, dropna)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minteresting_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hmoreau/Google Drive/Etudes/Master/Master-3/ADA/ADA-killer-team/project/scripts/data_import.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "review_books = import_interesting_cols(\n",
    "    review_books_path, DUMP_FOLDER,False, review_interesting_cols, max_count=MAXCOUNT)\n",
    "review_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.3 - 5-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving from : ../../Project-Data/dump/Books_asin_overall_unixReviewTime_ALL\n",
      "It took 00:00:00.693 to import the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2003-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000100039X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2002-10-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  overall unixReviewTime\n",
       "0  000100039X      5.0     2012-12-16\n",
       "1  000100039X      5.0     2003-12-11\n",
       "2  000100039X      5.0     2014-01-18\n",
       "3  000100039X      5.0     2011-09-27\n",
       "4  000100039X      5.0     2002-10-07"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_books = import_interesting_cols(\n",
    "    core_book_path,\n",
    "    DUMP_FOLDER,\n",
    "    False,\n",
    "    review_interesting_cols,\n",
    "    max_count=MAXCOUNT)\n",
    "core_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 0.2-Movies and TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_movie_path, review_movie_path, core_movie_path = get_paths(\n",
    "    1, DATA_FOLDER, META_FOLDER, CORE_FOLDER, REVIEWS_FOLDER, CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 0.2.1-Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_movie = import_interesting_cols(\n",
    "    meta_movie_path,DUMP_FOLDER, True, meta_interesting_cols, max_count=MAXCOUNT, dropna=False)\n",
    "meta_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 0.2.2-Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "review_movie = import_interesting_cols(\n",
    "    review_movie_path,\n",
    "    DUMP_FOLDER,\n",
    "    False,\n",
    "    review_interesting_cols,\n",
    "    max_count=100,\n",
    "    dropna=False)\n",
    "review_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "## 0.3-Electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_electronic_path, review_electronic_path, core_electronic_path = get_paths(\n",
    "    2, DATA_FOLDER, CORE_FOLDER, META_FOLDER, REVIEWS_FOLDER, CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 0.3.1-Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "meta_electronic = import_interesting_cols(\n",
    "    meta_electronic_path,\n",
    "    DUMP_FOLDER,\n",
    "    True,\n",
    "    meta_interesting_cols,\n",
    "    max_count=MAXCOUNT,\n",
    "    dropna=False)\n",
    "meta_electronic.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 0.3.2-Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "review_electronic = import_interesting_cols(\n",
    "    review_electronic_path,\n",
    "    DUMP_FOLDER,\n",
    "    False,\n",
    "    review_interesting_cols,\n",
    "    max_count=MAXCOUNT,\n",
    "    dropna=False)\n",
    "review_electronic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Detecting similar products\n",
    "In this section we try to obtain the products that are similar among a given category and to develop a systematic way to detect those similar products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1-Books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1.1.0 - Defining the dataset to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some books are sold in different formats : hard cover, pocket, electronic, etc. Therefore in order to compare them we will focus on the title and description that are the only two attributes that should be highly similar between the two different yet similar books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>imUrl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001055178</th>\n",
       "      <td>Master Georgie</td>\n",
       "      <td>Beryl Bainbridge seems drawn to disaster. Firs...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51ZSC6TK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000171287X</th>\n",
       "      <td>The Berenstains' B Book (Bright &amp; Early Books)</td>\n",
       "      <td>By Stan Berenstain and Jan Berenstain, Illustr...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31hjUxZu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000100039X</th>\n",
       "      <td>The Prophet</td>\n",
       "      <td>In a distant, timeless place, a mysterious pro...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/81ZKLPiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001473905</th>\n",
       "      <td>Rightly Dividing the Word</td>\n",
       "      <td>--This text refers to thePaperbackedition.</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61KPC59B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001714538</th>\n",
       "      <td>The Berenstain Bears on the Moon (Bright and E...</td>\n",
       "      <td>PreSchool-Grade 2 A delightful tale told in rh...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/A1zj84uC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "asin                                                            \n",
       "0001055178                                     Master Georgie   \n",
       "000171287X     The Berenstains' B Book (Bright & Early Books)   \n",
       "000100039X                                        The Prophet   \n",
       "0001473905                          Rightly Dividing the Word   \n",
       "0001714538  The Berenstain Bears on the Moon (Bright and E...   \n",
       "\n",
       "                                                  description  \\\n",
       "asin                                                            \n",
       "0001055178  Beryl Bainbridge seems drawn to disaster. Firs...   \n",
       "000171287X  By Stan Berenstain and Jan Berenstain, Illustr...   \n",
       "000100039X  In a distant, timeless place, a mysterious pro...   \n",
       "0001473905         --This text refers to thePaperbackedition.   \n",
       "0001714538  PreSchool-Grade 2 A delightful tale told in rh...   \n",
       "\n",
       "                                                        imUrl  \n",
       "asin                                                           \n",
       "0001055178  http://ecx.images-amazon.com/images/I/51ZSC6TK...  \n",
       "000171287X  http://ecx.images-amazon.com/images/I/31hjUxZu...  \n",
       "000100039X  http://ecx.images-amazon.com/images/I/81ZKLPiv...  \n",
       "0001473905  http://ecx.images-amazon.com/images/I/61KPC59B...  \n",
       "0001714538  http://ecx.images-amazon.com/images/I/A1zj84uC...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_asin = list(core_books['asin'].unique())\n",
    "\n",
    "# We delete all the rows where either the title or description is null and keep only core books\n",
    "core_meta_df = meta_books[meta_books['title'].notnull()]\n",
    "core_meta_df = core_meta_df[core_meta_df['description'].notnull()]\n",
    "core_meta_df = core_meta_df[core_meta_df['imUrl'].notnull()]\n",
    "core_meta_df = core_meta_df[core_meta_df['asin'].isin(core_asin)]\n",
    "book_desc_titles = core_meta_df[['asin','title','description','imUrl']]\n",
    "book_desc_titles = book_desc_titles.set_index(['asin'])\n",
    "book_desc_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_desc_titles.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We first try to experiment with tf-idf weights to find common titles among books. Due to the large size of the database, this task cannot be executed on all the books, we decided to focus as suggested by the dataset on the 5-core dataset. The 5 core dataset contains only products and reviews such that reviewers and products have at least 5-reviews. This will allow us in a first analysis to reduce the number of products that we consider. Since we will need to have at least 5 reviews anyway to look at the **Herding effect**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's explore a bit what the dataset contains. we have much informations (and in an heterogeneous manner) in the description. Therefore we might want to observe the name of the auhtor and the title when they are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 - Locality sensitive hashing\n",
    "Based on this [article](http://dataconomy.com/2017/06/locality-sensitive-hashing-pydata/), and following the theory that can be read at the chapter 3.4 of [Mining of massive datasets by Leskovec, Rajaraman and Milliway](http://infolab.stanford.edu/~ullman/mmds/book.pdf) we will try to find similar books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### The ```minhash```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to detect near similar books in this large datasets. To do so we would need to compare each of the attribute of a given book with all the others which is extremely computationaly expensive. There we will use LSH. Right now the title and description of the book have variable length depending on the books. To perform LSH we would like to have a fixed length representation of the document without modifying the semantics of document similarity.\n",
    "* first we introduce the principle of shingles. A shingle of 5-gram (hence we discard the last shingle as it only consists in the $<5$ last characters of the document) e.g. is a set of all possible 5-grams in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem',\n",
       " 'orem ',\n",
       " 'rem I',\n",
       " 'em Ip',\n",
       " 'm Ips',\n",
       " ' Ipsu',\n",
       " 'Ipsum',\n",
       " 'psum ',\n",
       " 'sum d',\n",
       " 'um do',\n",
       " 'm dol',\n",
       " ' dolo',\n",
       " 'dolor',\n",
       " 'olor ',\n",
       " 'lor s',\n",
       " 'or si',\n",
       " 'r sit',\n",
       " ' sit ',\n",
       " 'sit a',\n",
       " 'it am',\n",
       " 't ame']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = \"Lorem Ipsum dolor sit amet\"\n",
    "shingles = get_shingles(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_document = 'Lorem Ipsum dolor sit amet with some extra garbage'\n",
    "other_shingles = get_shingles(other_document)\n",
    "jaccard_dist(shingles,other_shingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Each document will still have a different number of shingles depending on its length. Therefore we wish to represent it using a *fixed length representation*. We will present now a function ```minhash``` that has a collision probability that is exactly the jaccard similarity (based on this [document](http://infolab.stanford.edu/~ullman/mmds/ch3.pdf) and following this [repo](https://github.com/mattilyra/LSH/blob/master/examples/Introduction.ipynb) . We explain this now :\n",
    "1. Suppose that the following dataframe is the boolean variable corresponding to whether or not a shingle belongs to a document\n",
    "2. the ```minhash``` of a document returns a random permutation of the rows and then the first row number it founds where the value is non 0.\n",
    "    * therefore row 1 for doc 1\n",
    "    * and row 0 for doc 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>shingleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc1  doc2  shingleID\n",
       "0     0     1          1\n",
       "1     1     1          2\n",
       "2     0     1          3\n",
       "3     0     0          4\n",
       "4     1     1          5\n",
       "5     1     0          6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_minhash = pd.DataFrame({'shingleID':[1,2,3,4,5,6],'doc1':[0,1,0,0,1,1],'doc2':[1,1,1,0,1,0]})\n",
    "ex_minhash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But this is for this particular permutation, if we had another one like below then the ```minhash``` would return :\n",
    "   * row 2 for doc1\n",
    "   * row 1 for doc2\n",
    "\n",
    "There are a lot of such permutations. Nevertheless we only care about having the same row for each document which mean we have collision of the ```minhash```. Therefore we have only two rows for which this happens : $\\text{shingleID} \\in \\{2,5\\}$. Hence the probability that the two doc have the same ```minhash``` (remmember that rows with two zeros do not count as they are not considered by ```minhash```) is the number of rows where both doc value is 1 divided by the number of rows where they are different : $\\frac{2}{5}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>shingleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc1  doc2  shingleID\n",
       "2     0     1          3\n",
       "3     0     0          4\n",
       "5     1     0          6\n",
       "1     1     1          2\n",
       "4     1     1          5\n",
       "0     0     1          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_minhash.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can chose the length of the fingerprint that is returned by the ```minhash```, as we increase the length we get less variance from the random initialisation of the ```minhasher``` but this also greatly increases the memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### The principle of LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lsh import minhash\n",
    "hasher = minhash.MinHasher(seeds=100, char_ngram=5)\n",
    "fingerprint0 = hasher.fingerprint('Lorem Ipsum dolor sit amet'.encode('utf8'))\n",
    "len(fingerprint0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Therefore the hash of a document is composed of a given (```seeds```) number of ```minhashes```. We divide this number of ```minhashes``` into a given number of parts (e.g. 5). Since every single ```minhash``` has the jaccard similarity probability of collision then each of the 5 parts will have this probability as well. These parts represent the **locality** in the term LSH.\n",
    "\n",
    "Then we hash the content of each part using a different hash function to obtain the *binID* that represents the **hashing** part of the method. Into each bin with *binID* we store the entire fingerprint of the document.\n",
    "\n",
    "The idea is then that we compare documents that fall in the same bins : we will compare their fingerprint which is equivalent to looking at their Jaccard similarity between shingle sets. Since not all documents will fall into the same bins we have reduced the number of potential candidates.\n",
    "\n",
    "Indeed we call :\n",
    "* ```seeds``` :  number of ```minihashes``` that compose the fingerprint\n",
    "* ```bands``` : the number of bins that we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding candidate duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>imUrl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001055178</th>\n",
       "      <td>Master Georgie</td>\n",
       "      <td>Beryl Bainbridge seems drawn to disaster. Firs...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51ZSC6TK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000171287X</th>\n",
       "      <td>The Berenstains' B Book (Bright &amp; Early Books)</td>\n",
       "      <td>By Stan Berenstain and Jan Berenstain, Illustr...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31hjUxZu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000100039X</th>\n",
       "      <td>The Prophet</td>\n",
       "      <td>In a distant, timeless place, a mysterious pro...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/81ZKLPiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001473905</th>\n",
       "      <td>Rightly Dividing the Word</td>\n",
       "      <td>--This text refers to thePaperbackedition.</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/61KPC59B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001714538</th>\n",
       "      <td>The Berenstain Bears on the Moon (Bright and E...</td>\n",
       "      <td>PreSchool-Grade 2 A delightful tale told in rh...</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/A1zj84uC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "asin                                                            \n",
       "0001055178                                     Master Georgie   \n",
       "000171287X     The Berenstains' B Book (Bright & Early Books)   \n",
       "000100039X                                        The Prophet   \n",
       "0001473905                          Rightly Dividing the Word   \n",
       "0001714538  The Berenstain Bears on the Moon (Bright and E...   \n",
       "\n",
       "                                                  description  \\\n",
       "asin                                                            \n",
       "0001055178  Beryl Bainbridge seems drawn to disaster. Firs...   \n",
       "000171287X  By Stan Berenstain and Jan Berenstain, Illustr...   \n",
       "000100039X  In a distant, timeless place, a mysterious pro...   \n",
       "0001473905         --This text refers to thePaperbackedition.   \n",
       "0001714538  PreSchool-Grade 2 A delightful tale told in rh...   \n",
       "\n",
       "                                                        imUrl  \n",
       "asin                                                           \n",
       "0001055178  http://ecx.images-amazon.com/images/I/51ZSC6TK...  \n",
       "000171287X  http://ecx.images-amazon.com/images/I/31hjUxZu...  \n",
       "000100039X  http://ecx.images-amazon.com/images/I/81ZKLPiv...  \n",
       "0001473905  http://ecx.images-amazon.com/images/I/61KPC59B...  \n",
       "0001714538  http://ecx.images-amazon.com/images/I/A1zj84uC...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_desc_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving from : ../../Project-Data/dump/candidate_dup_title_2_100_5_4\n",
      "Found 6476 items with possible duplicates.\n"
     ]
    }
   ],
   "source": [
    "dump_path = DUMP_FOLDER\n",
    "get_candidate = candidate_duplicates(book_desc_titles,dump_path,['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dangerous', 'Dangerous', 'Dangerous', 'Dangerous', 'Dangerous']\n",
      "[\"For years, Palmer's long, tall Texans have donned white hats and rescued ladies in distress. FBI Special Agent Mac Kilraven, the hunky hero of her bangup latest, is no exception. He reluctantly falls for doe-eyed 22-year-old Winnie Sinclair, but he's disturbed by a painting she gives him as a Christmas gift. It's eerily similar to a drawing his child, Melly, gave him before she and her mother were killed seven years ago. Kilraven's dedicated his life to catching the monster responsible, and now two cold cases converge as a dead body surfaces in the Little Carmichael River. There's no shortage of suspects—Winnie's drug-addicted uncle, the shady brother of a politician—as the investigation heats up and a development convinces Kilraven to ask Winnie to act as his wife when the trail leads them to the Bahamas. Palmer (Heartless) demonstrates, yet again, why she's the queen of desperado quests for justice and true love.(June)Copyright © Reed Business Information, a division of Reed Elsevier Inc. All rights reserved.\", \"A bestselling author of spicy historical and paranormal romance, Monica Burns penned her first short romance story at the age of nine when she selected the pseudonym she uses today.Her historical book awards include the 2011 RT BookReviews Reviewers Choice Award and the 2012 Gayle Wilson Heart of Excellence Award for Pleasure Me. She is also the recipient of the prestigious paranormal romance award, the 2011  PRISM Best of the Best award for Assassin's Heart.From the days when she hid her stories from her sisters to her first completed full-length manuscript, she always believed in her dream despite rejections and setbacks. A workaholic wife and mother, Monica believes it's possible for the good guy to win if they work hard enough.\", 'Nora Roberts is a bestselling author of more than 209 romance novels. She was the first author to be inducted into the Romance Writers of America Hall of Fame. As of 2011, her novels had spent a combined 861 weeks on theNew York TimesBestseller List, including 176 weeks in the number-one spot. Over 280 million copies of her books are in print, including 12 million copies sold in 2005 alone.--This text refers to theMass Market Paperbackedition.', 'Quick\\'s latest work, a flimsy and fairly routine piece, lacks the panache that made her earlier Regencies interesting. Prudence Merryweather and Sebastian Fleetwood, the \"legendary\" Earl of Angelstone, hit it off after meeting at a ball because they share an element of \"intellectual curiosity\": she hunts \"spectral phenomena,\" and he (courtesy of a Bow Street Runner who slips him intriguing cases) hunts criminals. When, at another party, Prue and Sebastian are caught pussyfooting in the hostess\\'s bedroom, an impromptu engagement results, giving them ample opportunity to poke into each other\\'s investigations. Sebastian, whose parents were ill-treated by the family, has wanted revenge on his kin for years; when his aunt publicly insults Prue, he is ready to exploit his role as head of the family and get them booted out of society. However, Prue\\'s moderating influence persuades him to set aside revenge and act as a benevolent patriarch, a scenario that may sound familiar to readers of Wildest Hearts, this author\\'s most recent contemporary romance (written as Jayne Ann Krentz).Copyright 1993 Reed Business Information, Inc.', 'Gr 7 Up—Her middle name may be Danger, but Maisie \"Danger\" Brown doesn\\'t seem a likely action heroine. She is a homeschooled half-Latina science geek with a special love for physics and astronomy, and she has an artificial arm. When she wins a contest to go to astronaut camp with other teens, her life changes dramatically. Her team gets an opportunity to go up in a space elevator, and she and four others, including Wilder, the boy she\\'s crushing on, are exposed to alien artifacts or \"tokens,\" which enter their bodies and give them superpowers. Maisie becomes a tech whiz, one teen becomes superstrong and beastlike, another is able to shoot objects from her fingers, one teammate gains the ability to grow armor and weaponry from his body, and Wilder becomes the Thinker, a mastermind who can direct them all on a mission envisioned by the aliens who created the tokens. But what is the group\\'s ultimate purpose? Will they survive the alien mission? And will they be able to escape the grasp of the humans competing to exploit them and the alien technology, including Wilder\\'s own unscrupulous father? This fast-paced science fiction novel with echoes of the \"Fantastic Four\" comics doesn\\'t let up for a moment. Maisie is a strong, smart heroine with a wry sense of humor, and readers will be rooting for her to save the world. A must-read for fans of superhero adventures.—Kathleen E. Gruver, Burlington County Library, Westampton, NJ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://ecx.images-amazon.com/images/I/41DL%2BXpGFeL.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://ecx.images-amazon.com/images/I/51mmxEDULkL.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://ecx.images-amazon.com/images/I/51397C7VMPL.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://ecx.images-amazon.com/images/I/51mzKkkipQL.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"http://ecx.images-amazon.com/images/I/51BEqZbO%2B%2BL.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's quickly oberve the type of data that we obtain\n",
    "element_to_inspect = 67\n",
    "similarity_keys = list(get_candidate.keys())\n",
    "print(get_titles(similarity_keys[element_to_inspect],get_candidate,book_desc_titles))\n",
    "print(get_desc(similarity_keys[element_to_inspect],get_candidate,book_desc_titles))\n",
    "display_images(similarity_keys[element_to_inspect],get_candidate,book_desc_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the books can greatly vary eventhough they have the same title. Also it seems hard to extract any meaningful data from their description therefore we need to use the Amazon API to try to get the data we are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to use Amazon API to get structured data\n",
    "Because of the heterogeneous nature of the data in description we use Amazon API to obtain consistent informations like the name of authors, ISBN etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Still in construction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.python.org/pypi/python-amazon-simple-product-api\n",
    "Access_key_ID = \"AKIAIHFTJY5L2ETOYLWQ\"\n",
    "Secret_access_key = \"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\"\n",
    "Associat_tag = \"hmoreau-21\"\n",
    "#https://www.amazon.co.uk/dp/<ASIN>/\n",
    "#https://www.amazon.com/dp/<ASIN>/\n",
    "from amazon.api import AmazonAPI\n",
    "amazon = AmazonAPI(Access_key_ID, Secret_access_key, Associat_tag, Region ='FR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1490595635'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = amazon.lookup(ItemId='1490595635')\n",
    "products.isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bliss []\n",
      "Bliss ['Hilary Fields']\n",
      "Bliss ['Lauren Myracle']\n",
      "Bliss ['Kathryn Littlewood']\n",
      "Bliss ['Opal Carew']\n"
     ]
    }
   ],
   "source": [
    "asins = ','.join([asin for asin,title in asin_title])\n",
    "products = amazon.lookup(ItemId=asins)\n",
    "for p in products:\n",
    "    print(p.title,p.authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we are already doing quite well to detect candidate similars but indeed those are not the same and we now need to go further and define a suite of tools that we can use to check between those candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Here I put all my work in progress that didn't show any results yet but could be useful later on.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rudy\n",
      "Lopez\n",
      "Christopher\n",
      "Jordan\n",
      "Dorner\n",
      "Dorner\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger(DATA_FOLDER+'stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "DATA_FOLDER+'stanford-ner/stanford-ner.jar',encoding='utf-8')\n",
    "\n",
    "text = \"\"\"\n",
    "A multi-agency manhunt is under way across several states and Mexico after\n",
    "police say the former Los Angeles police officer suspected in the murders of a\n",
    "college basketball coach and her fiancÃ© last weekend is following through on\n",
    "his vow to kill police officers after he opened fire Wednesday night on three\n",
    "police officers, killing one.\n",
    "\"In this case, we're his target,\" Sgt. Rudy Lopez from the Corona Police\n",
    "Department said at a press conference.\n",
    "The suspect has been identified as Christopher Jordan Dorner, 33, and he is\n",
    "considered extremely dangerous and armed with multiple weapons, authorities\n",
    "say. The killings appear to be retribution for his 2009 termination from the\n",
    " Los Angeles Police Department for making false statements, authorities say.\n",
    "Dorner posted an online manifesto that warned, \"I will bring unconventional\n",
    "and asymmetrical warfare to those in LAPD uniform whether on or off duty.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rudy\n",
      "Lopez\n",
      "Christopher\n",
      "Jordan\n",
      "Dorner\n",
      "Dorner\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenize(text):\n",
    "    chunks = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "    \n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "for word,tag in classified_text:\n",
    "    if(tag=='PERSON'):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.1.0 - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#nltk.download('punkt') # if necessary...\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    '''remove punctuation, lowercase, stem'''\n",
    "    toReturn = stem_tokens(\n",
    "        nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "    return toReturn\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
